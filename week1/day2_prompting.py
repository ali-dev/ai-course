# -*- coding: utf-8 -*-
"""day2_prompting_

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VqqGeHxEDb3T3NIh6ofkkKoeS_yHHxIn
"""

# pip install langchain_core

# pip install langchain_openai


import os
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI, OpenAI
key = os.getenv("OPENAI_API_KEY")
llm = OpenAI(api_key= key)
chat_model= ChatOpenAI(model="gpt-3.5-turbo", api_key=key, temperature= .10)

text= "What is a createve naem for a mythology based escape room?"
messages = [HumanMessage(content= text)]

response_llm = llm.invoke(messages)
print(response_llm)
print(type(response_llm))
print("*******")

#vs
response_chat = chat_model.invoke(messages)
print(response_chat)
print(type(response_chat))

system_text = "You are Madonna and you are singing your advice to us in your answer."
messages = [ SystemMessage(content = system_text), HumanMessage(content= text)]

response_llm = llm.invoke(messages)
print(response_llm)
print(type(response_llm))
print("*******")

#vs
response_chat = chat_model.invoke(messages)
print(response_chat)
print(type(response_chat))

#one shot learning

#few show learnings

#zero shot learning

def generate_response_zero_shot(review):
    prompt = f"As a customer support representative, write a response to the following review:\n\n{review}\n\nResponse:"
    messages = [SystemMessage(content=prompt)]
    response = llm.invoke(messages)
    return response

review = "I am very disappointed with the quality of your product. It broke after just a few days of use."

# # Generate responses
zero_shot_response = generate_response_zero_shot(review)

# Print responses
print("Zero-Shot Response:")
print(zero_shot_response)

from langchain import PromptTemplate

demo_template='''I want you to act as a acting financial advisor for people.
In an easy way, explain the basics of {financial_concept}.'''


prompt=PromptTemplate(
    input_variables=['financial_concept'],
    template=demo_template
    )


prompt.format(financial_concept='income tax')

from langchain.chains import LLMChain

chain1 = LLMChain(llm=llm, prompt=prompt)

chain1({"financial_concept":'plumbing'})

template='''In an easy way translate the following sentence '{sentence}' into {target_language}'''
language_prompt = PromptTemplate(
    input_variables=["sentence",'target_language'],
    template=template,
)
language_prompt.format(sentence="How are you",target_language='gaelic')

chain2=LLMChain(llm=llm, prompt=language_prompt)

chain2({'sentence':"Hello How are you",'target_language':'gaelic'})

from langchain import FewShotPromptTemplate

examples = [
    {"artist":"Colter Wall", "genre":"Country"},
    {"artist":"DOD", "genre":"goth"},
    {"artist":"Omah Lay", "genre":"afro beats"}
]

example_formatter_template ="""Artist: {artist}
Genre: {genre}
"""

example_prompt = PromptTemplate(
    input_variables = ['artist', 'genre'],
    template= example_formatter_template,
)

# chain = LLMChain(llm=llm, prompt=example_prompt)
# chain({'artist':'shakira', })

# Finally, we create the `FewShotPromptTemplate` object.
few_shot_prompt = FewShotPromptTemplate(
    # These are the examples we want to insert into the prompt.
    examples=examples,
    # This is how we want to format the examples when we insert them into the prompt.
    example_prompt=example_prompt,
    prefix="Give the genre for each album\n",
    suffix="What's the genre for {input}?",
    input_variables = ['input'],
    example_separator="\n")

print(few_shot_prompt.format(input="Shakira"))

chain= LLMChain(llm=llm,prompt=few_shot_prompt)
chain({'input':"Shakira"})

